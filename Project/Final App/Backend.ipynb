{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "global user_lyrics_tfidf\n",
    "userLyrics = \"time rain parade watch hope explode landmines ask help people turn away your living far away truth your believing lie surprise sleep night drowning prize made feel welcome welcome make forget poison running vein may say love love lie mess you made dont let dont let pull dont let dont let pull dont let\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicLyricsProcessing(userLyrics):\n",
    "    #Everything in lowercase\n",
    "    lowerCase = lambda x: \" \".join(x.lower() for x in str(x).split())\n",
    "    userLyrics = lowerCase(userLyrics)\n",
    "\n",
    "    #Removing punctuation that does not add meaning to the song\n",
    "    userLyrics = userLyrics.replace('[^\\w\\s]','')\n",
    "    \n",
    "    #Removing of stop words\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    stop = stopwords.words('english')\n",
    "    removeStopWords = lambda x: \" \".join(x for x in str(x).split() if x not in stop)\n",
    "    userLyrics = removeStopWords(userLyrics)\n",
    "    \n",
    "    #Correction of Spelling mistakes\n",
    "    from textblob import TextBlob\n",
    "    spellingMistake = lambda x: str(TextBlob(x).correct())\n",
    "    userLyrics = spellingMistake(userLyrics)\n",
    "    \n",
    "    #Lemmatization is basically converting a word into its root word. It is preferred over Stemming.\n",
    "    from textblob import Word\n",
    "    lemmatize = lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])\n",
    "    userLyrics = lemmatize(userLyrics)\n",
    "    \n",
    "    #CountVectorization of user lyrics\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    user_bow = CountVectorizer(max_features=100000,\n",
    "                          lowercase=True,\n",
    "                          ngram_range=(1,1),\n",
    "                          analyzer = \"word\").fit([userLyrics])\n",
    "    \n",
    "    #Bag of Words conversion of user lyrics\n",
    "    user_lyrics_bow = bow.transform([userLyrics])\n",
    "    \n",
    "    #Tf-idf transforming of user lyrics\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    user_tfidf_transformer = TfidfTransformer().fit(user_lyrics_bow)\n",
    "    user_lyrics_tfidf = user_tfidf_transformer.transform(user_lyrics_bow)\n",
    "    return user_lyrics_tfidf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of vocab size:  94381\n",
      "Shape of Sparse Matrix:  (2580, 94381)\n",
      "188482\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=100000,\n",
    "                      lowercase=True,\n",
    "                      ngram_range=(1,2),\n",
    "                      analyzer = \"word\").fit(csv['Lyrics'].values.astype(str))\n",
    "\n",
    "print(\"lenth of vocab size: \",len(bow.vocabulary_))\n",
    "\n",
    "lyrics_bow = bow.transform(csv['Lyrics'].values.astype(str))\n",
    "print('Shape of Sparse Matrix: ', lyrics_bow.shape)\n",
    "print(lyrics_bow.nnz)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer().fit(lyrics_bow)\n",
    "lyrics_tfidf = tfidf_transformer.transform(lyrics_bow)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(lyrics_tfidf, csv['hitOrNot'])\n",
    "\n",
    "model.fit(lyrics_tfidf, csv['hitOrNot'])\n",
    "\n",
    "user_tfidf = basicLyricsProcessing(userLyrics)\n",
    "predictions = model.predict(user_tfidf)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time rain parade watch hope explode landmines ask help people turn away your living far away truth your believing lie surprise sleep night drowning prize made feel welcome welcome make forget poison running vein may say love love lie mess you made dont let dont let pull dont let dont let pull dont let']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[userLyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
